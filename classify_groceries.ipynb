{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import __version__\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
        "NB_EPOCHS = 10\n",
        "BAT_SIZE = 32\n",
        "FC_SIZE = 1024\n",
        "DROP_RT = 0.5\n",
        "NB_IV3_LAYERS_TO_FREEZE = 172\n",
        "\n\n",
        "def get_nb_files(directory):\n",
        "  \"\"\"Get number of files by searching directory recursively\"\"\"\n",
        "  if not os.path.exists(directory):\n",
        "    return 0\n",
        "  cnt = 0\n",
        "  for r, dirs, files in os.walk(directory):\n",
        "    for dr in dirs:\n",
        "      cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "  return cnt\n",
        "\n\n",
        "def setup_to_transfer_learn(model, base_model):\n",
        "  \"\"\"Freeze all layers and compile the model\"\"\"\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n\n",
        "def add_new_last_layer(base_model, nb_classes):\n",
        "  \"\"\"Add last layer to the convnet\n",
        "\n",
        "  Args:\n",
        "    base_model: keras model excluding top\n",
        "    nb_classes: # of classes\n",
        "\n",
        "  Returns:\n",
        "    new keras model with last layer\n",
        "  \"\"\"\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(FC_SIZE, activation='relu')(x)\n",
        "  x = Dropout(DROP_RT)(x)\n",
        "  predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  return model\n",
        "\n\n",
        "def setup_to_finetune(model):\n",
        "  \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
        "\n",
        "  note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
        "\n",
        "  Args:\n",
        "    model: keras model\n",
        "  \"\"\"\n",
        "  for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
        "     layer.trainable = False\n",
        "  for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
        "     layer.trainable = True\n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n\n",
        "def train(train_dir, val_dir,\n",
        "        nb_epoch=NB_EPOCHS, batch_size=BAT_SIZE,\n",
        "        output_model_file='inceptionv3-ft.model',\n",
        "        plot='store_true'):\n",
        "  \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
        "  nb_train_samples = get_nb_files(train_dir)\n",
        "  nb_classes = len(glob.glob(train_dir + \"/*\"))\n",
        "  nb_val_samples = get_nb_files(val_dir)\n",
        "  nb_epoch = int(nb_epoch)\n",
        "  batch_size = int(batch_size)\n",
        "\n",
        "  # data prep\n",
        "  train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True\n",
        "  )\n",
        "  test_datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True\n",
        "  )\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  print(train_generator.class_indices)\n",
        "\n",
        "  # setup model\n",
        "  base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
        "  model = add_new_last_layer(base_model, nb_classes)\n",
        "\n",
        "  # transfer learning\n",
        "  setup_to_transfer_learn(model, base_model)\n",
        "\n",
        "  history_tl = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=nb_epoch,\n",
        "    steps_per_epoch=nb_train_samples/batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_val_samples/batch_size,\n",
        "    class_weight='auto')\n",
        "\n",
        "  # fine-tuning\n",
        "  setup_to_finetune(model)\n",
        "\n",
        "  history_ft = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples/batch_size,\n",
        "    epochs=nb_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_val_samples/batch_size,\n",
        "    class_weight='auto')\n",
        "\n",
        "  model.save(output_model_file)\n",
        "\n",
        "  if plot:\n",
        "    plot_training(history_ft)\n",
        "\n\n",
        "def plot_training(history):\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'r.')\n",
        "  plt.plot(epochs, val_acc, 'r')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'r.')\n",
        "  plt.plot(epochs, val_loss, 'r-')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dir='/data/train', val_dir='/data/validation')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
        "\n",
        "def predict_dir(model, predict_dir):\n",
        "  \"\"\"Run model prediction on image\n",
        "  Args:\n",
        "    model: keras model\n",
        "    img: PIL format image\n",
        "  Returns:\n",
        "    list of predicted labels and their probabilities\n",
        "  \"\"\"\n",
        "  # data prep\n",
        "  predict_datagen =  ImageDataGenerator()\n",
        "\n",
        "  predict_generator = predict_datagen.flow_from_directory(\n",
        "    predict_dir,\n",
        "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "    batch_size=256,\n",
        "    class_mode=None,  # only data, no labels\n",
        "    shuffle=False  # keep data in same order as labels\n",
        "  )\n",
        "    \n",
        "  print(predict_generator.class_indices)\n",
        "    \n",
        "  num_files = len(predict_generator.filenames)\n",
        "  print(predict_generator.filenames)\n",
        "    \n",
        "  preds = model.predict_generator(\n",
        "    predict_generator,\n",
        "    num_files,\n",
        "    verbose=1)\n",
        "\n  return preds"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/test'\n",
        "model = 'inceptionv3-ft.model'\n",
        "\n",
        "model = load_model(model)\n",
        "preds = predict_dir(model, test_dir)\n",
        "classes = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "test_filenames = os.listdir('/test/unknown')\n",
        "\n",
        "class_indices = {'nuts': 14, 'chocolate': 5, 'tomatosauce': 22, 'rice': 17, 'soda': 18, 'candy': 2, 'milk': 13, 'juice': 12, 'sugar': 20, 'cereal': 3, 'vinegar': 23, 'water': 24, 'spices': 19, 'pasta': 16, 'fish': 8, 'cake': 1, 'coffee': 6, 'chips': 4, 'honey': 10, 'beans': 0, 'corn': 7, 'flour': 9, 'tea': 21, 'jam': 11, 'oil': 15}\n",
        "class_indices = dict(zip(class_indices.values(),class_indices.keys()))\n",
        "\n",
        "classes = preds.argmax(axis=-1)\n",
        "classes = [class_indices[x] for x in classes]\n",
        "\n",
        "df = pd.DataFrame(list(zip(test_filenames, classes)))\n",
        "df[0] = df[0].str.rstrip('.png')\n",
        "\n",
        "df.to_csv('predictions.csv', sep=',', header=False, index=False)\n",
        "\nprint(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               0          1\n",
            "0     test_1307c  chocolate\n",
            "1     test_1234d        tea\n",
            "2     test_1129a  chocolate\n",
            "3     test_1056b     coffee\n",
            "4     test_1145c     coffee\n",
            "5     test_1218b        tea\n",
            "6     test_1072d        tea\n",
            "7     test_1315d     coffee\n",
            "8     test_1137b        tea\n",
            "9     test_1064c        tea\n",
            "10    test_1048a        tea\n",
            "11    test_1153d        tea\n",
            "12    test_1226c        tea\n",
            "13    test_1363a       rice\n",
            "14    test_1290b     coffee\n",
            "15    test_1282a  chocolate\n",
            "16    test_1371b        tea\n",
            "17    test_1092b     coffee\n",
            "18    test_1165a        tea\n",
            "19    test_1416b       rice\n",
            "20    test_1270d     coffee\n",
            "21    test_1343c  chocolate\n",
            "22    test_1254b     coffee\n",
            "23    test_1181c     coffee\n",
            "24    test_1327a  chocolate\n",
            "25    test_1432d     coffee\n",
            "26    test_1246a     coffee\n",
            "27    test_1173b     coffee\n",
            "28    test_1424c        tea\n",
            "29    test_1351d     coffee\n",
            "...          ...        ...\n",
            "1702  test_1242d     coffee\n",
            "1703  test_1064b        tea\n",
            "1704  test_1137a        tea\n",
            "1705  test_1161d     coffee\n",
            "1706  test_1307b  chocolate\n",
            "1707  test_1234c        tea\n",
            "1708  test_1056a  chocolate\n",
            "1709  test_1323d        tea\n",
            "1710  test_1218a  chocolate\n",
            "1711  test_1072c       rice\n",
            "1712  test_1145b        tea\n",
            "1713  test_1117c  chocolate\n",
            "1714  test_1044d     coffee\n",
            "1715  test_1028b        tea\n",
            "1716  test_1206d  chocolate\n",
            "1717  test_1125d     coffee\n",
            "1718  test_1109b        tea\n",
            "1719  test_1036c     coffee\n",
            "1720  test_1262b        tea\n",
            "1721  test_1335a  chocolate\n",
            "1722  test_1173a        tea\n",
            "1723  test_1424b     coffee\n",
            "1724  test_1351c     coffee\n",
            "1725  test_1092a     coffee\n",
            "1726  test_1416a        tea\n",
            "1727  test_1270c        tea\n",
            "1728  test_1343b        tea\n",
            "1729  test_1254a     coffee\n",
            "1730  test_1181b     coffee\n",
            "1731  test_1432c     coffee\n",
            "\n",
            "[1732 rows x 2 columns]\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}